{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asnIkqOZmFxB"
   },
   "source": [
    "## Data completion | Augmentation\n",
    "To train the network better on a small dataset, you can use data augmentation, a technique for modifying the images in the training set and adding them to the set. So, the network will receive more different examples for training and, accordingly, will show better results.\n",
    "\n",
    "\n",
    "The algorithm applies the same random affine changes to each i-th image in each subfolder in the dataset folder and save new images as PNG files in augmented dataset folder.\n",
    "\n",
    "\n",
    "### Run:\n",
    "0. Install requirements.\n",
    "1. Put the folders with the images that you want to augment into the Dataset folder(by default: \"Dataset\" folder). Each folder must have the same number of images.\n",
    "2. Open Data_Augmentation.ipynb with program, which can execute ipynb files, for example, Jupiter Notebook.\n",
    "3. Optionally, tune settings of transformations on images in \"Settings\" section.\n",
    "4. Run all lines in notebook.\n",
    "5. Augmented dataset will be placed in the same folder with script in new folder (by default: \"AugmentedDataset\" folder). Names of pictures have form: \"originalName_numberInAlphabeticalOrder_iterationNumber\".\n",
    "\n",
    "\n",
    "### Requirements:\n",
    "- Python 3+\n",
    "- Requires PIL library\n",
    "\n",
    "\n",
    "### Settings:\n",
    "- Folder dataset: \"Dataset\" (can be changed in train_dir)\n",
    "- Output folder: \"AugmentedDataset\" (can be changed in result_path)\n",
    "- Dataset increase multiplier: 2 (can be changed in multiple_output_images)\n",
    "- Output images size: 1024x1024 (can be changed in img_width, img_height)\n",
    "\n",
    "\n",
    "- You can edit the parameters of changing images in the settings section: rotation, shift, zoom, reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQC_xsKRPt2R"
   },
   "source": [
    "## Settings\n",
    "Let's specify the paths to the folders with images, their desired size and settings of transformations on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gKjw6F-4Pt2T"
   },
   "outputs": [],
   "source": [
    "train_dir = F'Dataset'             # Path from the script file to the folder with the folders with images\n",
    "result_path = F'AugmentedDataset'  # Output folder name\n",
    "multiple_output_images = 20        # How many times to increase the dataset\n",
    "img_width, img_height = 1024, 1024 # Output image size\n",
    "\n",
    "rotation_range = 270               # Image rotation in degrees\n",
    "rotation_range_multiple = 90       # Image rotation multiples in degrees\n",
    "width_shift_range = 0.2            # Horizontal Shift\n",
    "height_shift_range = 0.2           # Vertical Shift\n",
    "zoom_range = 0.1                   # Zoom in / out\n",
    "horizontal_mirror = True           # Horizontal Mirror\n",
    "vertical_mirror = True             # Vertical Mirror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm_81fnhomzL"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rtHqylV-omza"
   },
   "outputs": [],
   "source": [
    "from os import makedirs \n",
    "from os import listdir\n",
    "import random\n",
    "from shutil import rmtree \n",
    "from PIL import Image # import the Python Image processing Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzLpjhv_Pt3J"
   },
   "source": [
    "## Making augmented dataset\n",
    "Create a folder for the augmented dataset and generate equally modified images in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom function\n",
    "def zoom_at(img, x, y, zoom):\n",
    "    w, h = img.size\n",
    "    zoom2 = zoom * 2\n",
    "    img = img.crop((x - w / zoom2, y - h / zoom2, \n",
    "                    x + w / zoom2, y + h / zoom2))\n",
    "    return img.resize((w, h), Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in dataset dir: ['Expert', 'sample_1', 'sample_2', 'sample_3']\n",
      "Number of files in Dataset/Expert: 100\n",
      "Progress: 0/20\n",
      "Progress: 1/20\n",
      "Progress: 2/20\n",
      "Progress: 3/20\n",
      "Progress: 4/20\n",
      "Progress: 5/20\n",
      "Progress: 6/20\n",
      "Progress: 7/20\n",
      "Progress: 8/20\n",
      "Progress: 9/20\n",
      "Progress: 10/20\n",
      "Progress: 11/20\n",
      "Progress: 12/20\n",
      "Progress: 13/20\n",
      "Progress: 14/20\n",
      "Progress: 15/20\n",
      "Progress: 16/20\n",
      "Progress: 17/20\n",
      "Progress: 18/20\n",
      "Progress: 19/20\n",
      "\n",
      "Done. Augmented data in AugmentedDataset\n"
     ]
    }
   ],
   "source": [
    "dirs = listdir(path = train_dir)                       # list of dirs\n",
    "print(f'Folders in dataset dir: {dirs}')\n",
    "\n",
    "dirPath = f'{train_dir}/{dirs[0]}'                        # check correctness of data: number of files in dirs must be equak\n",
    "numberFiles = len(listdir(path = dirPath))\n",
    "print(f'Number of files in {dirPath}: {numberFiles}')\n",
    "for dir_ in dirs:\n",
    "    dirPath = f'{train_dir}/{dir_}'\n",
    "    if(len(listdir(path = dirPath)) != numberFiles):\n",
    "        print(f'ERROR: not equal number of files in dirs')\n",
    "\n",
    "# Create output dir\n",
    "try:\n",
    "    rmtree(result_path, ignore_errors=False, onerror=None)\n",
    "except:\n",
    "    print(\"Warning: Can't remove result dir\")\n",
    "try:\n",
    "    makedirs(result_path)\n",
    "except:\n",
    "    print(\"Warning: Can't create result dir\")\n",
    "    \n",
    "for multiple in range(multiple_output_images):\n",
    "    print(f'Progress: {multiple}/{multiple_output_images}')\n",
    "    for i in range(numberFiles):                                                       # rotate and zoom image\n",
    "        randRotate = random.randint(0, rotation_range / rotation_range_multiple) * rotation_range              # rotation\n",
    "        randZoom = 1 + (-1)**random.randint(1, 2) * random.random() * zoom_range                               # zoom\n",
    "        randHorizontalShift = (-1)**random.randint(1, 2) * random.random() * width_shift_range * img_width     # horizontal shift\n",
    "        randVerticalShift = (-1)**random.randint(1, 2) * random.random() * height_shift_range * img_height     # vertical shift\n",
    "        \n",
    "        for dir_ in dirs:                                                              # do same changes on photo[i] for all dirs\n",
    "            dirPath = f'{train_dir}/{dir_}'\n",
    "            img = Image.open(dirPath +'/'+ listdir(path = dirPath)[i])                                        # open image\n",
    "            img = img.resize((img_width, img_height))                                                         # resize image\n",
    "            if(horizontal_mirror):\n",
    "                img = img.transform(img.size, Image.AFFINE, (-1, 0, img_width, 0, 1, 0))                      # horizontal mirror image\n",
    "            if(vertical_mirror):\n",
    "                img = img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, -1, img_height))                     # vertical mirror image\n",
    "            img = zoom_at(img, img_width / 2, img_height / 2, randZoom)                                       # zoom image\n",
    "            img = img.transform(img.size, Image.AFFINE, (1, 0, randHorizontalShift, 0, 1, randVerticalShift)) # shift image\n",
    "            img = img.rotate(randRotate)                                                                      # rotate image\n",
    "            img.save(f'{result_path}/{listdir(path=dirPath)[i].split(\".\")[0]}_{i}_{multiple}.png', \"PNG\")     # save image\n",
    "\n",
    "print(f'\\nDone. Augmented data in {result_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Data Augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
